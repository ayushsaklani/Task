{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D CNN for MRI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root_zero/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholders(shape,n_Ch,n_Y):\n",
    "   \n",
    "    n_D,n_R,n_C=shape\n",
    "    X = tf.placeholder(shape=(None, n_D,n_R,n_C,n_Ch),dtype='float',name=\"X\")  #input placeholder \n",
    "    Y= tf.placeholder(shape=(None,n_Y),dtype=\"float\",name=\"Y\")   #output placeholder\n",
    "    \n",
    "    return X,Y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X:0\", shape=(?, 30, 64, 64, 3), dtype=float32)\n",
      "Y = Tensor(\"Y:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "shape= [30,64,64]\n",
    "X,Y= placeholders(shape,3,1)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_Ch):\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\",[5,5,5,n_Ch,8],initializer=tf.contrib.layers.xavier_initializer(seed = 2)) #weight for hidden layer1\n",
    "    W2 = tf.get_variable(\"W2\",[3,3,3,8,20],initializer=tf.contrib.layers.xavier_initializer(seed = 2)) #weight for hidden layer2\n",
    "    W3 = tf.get_variable(\"W3\",[2,2,2,20,30],initializer=tf.contrib.layers.xavier_initializer(seed = 2))#weight for hidden layer3\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                 \"W3\":W3}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.03683396 -0.01747156  0.0626035  -0.0396937   0.06305829  0.01175921\n",
      "  -0.03583478 -0.04021666]\n",
      " [-0.02612016 -0.04518278  0.02921299  0.00691286  0.01202715  0.02822192\n",
      "   0.01201055 -0.05580938]\n",
      " [ 0.01291112 -0.04221325 -0.04847242  0.03618843  0.01366609 -0.05239179\n",
      "  -0.04156421  0.04751361]]\n",
      "W2 = [[ 0.02904094 -0.01707939 -0.01908917  0.02339057 -0.01865383  0.07799385\n",
      "   0.02017494 -0.07534269  0.08736709  0.0246733   0.01382897 -0.05351781\n",
      "  -0.06159095 -0.05348472 -0.01091406 -0.0707201  -0.03715204 -0.0560387\n",
      "   0.01583225  0.08135979]\n",
      " [ 0.07302515  0.02072123 -0.02753112  0.05069304 -0.06763384 -0.04402454\n",
      "   0.02812131 -0.02235015  0.03556526  0.04793748  0.07305662  0.00805596\n",
      "  -0.06419431 -0.05185527 -0.08084551  0.01047558  0.05220492  0.03698102\n",
      "   0.04131581 -0.05287965]\n",
      " [-0.05757724  0.00040872 -0.01496833 -0.01075824 -0.03189651  0.05547701\n",
      "  -0.08840938  0.06412901 -0.05141369  0.06284249  0.06560351  0.04337619\n",
      "   0.01627102  0.05671664 -0.0011998  -0.08239631 -0.02994777  0.07580873\n",
      "   0.06155631  0.06950228]\n",
      " [ 0.03817794  0.05718648 -0.08371194  0.03484325  0.06832966  0.06855924\n",
      "   0.02640965 -0.05052853  0.05960208 -0.08164386  0.07224759  0.02972262\n",
      "  -0.01156536  0.01326378  0.07657051  0.06970733 -0.00064979 -0.03334846\n",
      "  -0.02688519  0.00300842]\n",
      " [-0.08090477 -0.06711654 -0.05199934  0.02178881  0.00965223  0.04269895\n",
      "   0.08262405 -0.08080237 -0.04071594 -0.0441745   0.07494053 -0.0372908\n",
      "  -0.01552513  0.04071103 -0.06895535  0.0477782  -0.00323885  0.0843004\n",
      "  -0.00288679  0.03219742]\n",
      " [ 0.08290184  0.04890612  0.07187191 -0.04343819 -0.04450066 -0.01984822\n",
      "   0.00081829 -0.05551218  0.02963039 -0.02715037 -0.03270517 -0.00311623\n",
      "   0.06795622  0.04850088  0.01057334  0.07807665  0.01934541 -0.02677158\n",
      "   0.07396446 -0.01319817]\n",
      " [-0.03774104 -0.04852999 -0.00873973 -0.06136253 -0.0656129   0.0377159\n",
      "  -0.05357204 -0.02181768 -0.01225738 -0.01053271 -0.04960903 -0.05419688\n",
      "   0.06490403 -0.07895318  0.0224946   0.07543717  0.06928939 -0.03541395\n",
      "  -0.07495179 -0.03055376]\n",
      " [-0.02850688 -0.0823056  -0.06916544 -0.02505334 -0.04122007  0.04241198\n",
      "   0.07008475 -0.03280085  0.00155099 -0.02570781 -0.0694806   0.03436163\n",
      "  -0.07247745 -0.01530006  0.00645718 -0.08645296 -0.0474609  -0.060337\n",
      "   0.03751926  0.01735093]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters(3)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,1]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Prop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,parameters):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    \n",
    "    \n",
    "    _,n_D,n_R,n_C,_=X.shape\n",
    "    #Convolution layer\n",
    "    Z1 = tf.nn.conv3d(X,W1, strides = [1,1,1,1,1], padding = 'SAME')\n",
    "    #Relu\n",
    "    A1=tf.nn.relu(Z1)\n",
    "    #Pooling Layer\n",
    "    P1 = tf.nn.max_pool3d(A1, ksize = [1,8,8,8,1], strides = [1,8,8,8,1], padding = 'SAME')\n",
    "    #Convolution layer 2\n",
    "    Z2 = tf.nn.conv3d(P1,W2, strides = [1,1,1,1,1], padding = 'SAME')\n",
    "    #Relu 2\n",
    "    A2=tf.nn.relu(Z2)\n",
    "    #Pooling Layer2\n",
    "    P2 = tf.nn.max_pool3d(A2, ksize = [1,5,5,5,1], strides = [1,5,5,5,1], padding = 'SAME')\n",
    "    #Convolution layer 3\n",
    "    Z3 = tf.nn.conv3d(P2,W3, strides = [1,1,1,1,1], padding = 'SAME')\n",
    "    #Relu 3\n",
    "    A3=tf.nn.relu(Z3)\n",
    "    #Pooling Layer 3\n",
    "    P3 = tf.nn.max_pool3d(A3, ksize = [1,2,2,2,1], strides = [1,2,2,2,1], padding = 'SAME')\n",
    "    #fullyconnected layer\n",
    "    Z3=tf.contrib.layers.fully_connected(P3,1,activation_fn=None)\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = [[[[[0.8273127]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.8643329]]]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "   \n",
    "    X, Y = placeholders(shape,3,1)\n",
    "    parameters = initialize_parameters(3)\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z3, {X: np.random.randn(2,30,64,64,3), Y: np.random.randn(2,1)})\n",
    "    print(\"Z3 = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def com_cost(Z3, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y)) #cost function to calculate loss at each time step\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [[[[[0.8273127]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.8643329]]]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "   \n",
    "    X, Y = placeholders(shape,3,1)\n",
    "    parameters = initialize_parameters(3)\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z3, {X: np.random.randn(2,30,64,64,3), Y: np.random.randn(2,1)})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "\n",
    "    \n",
    "    m = X.shape[0]                  \n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    " \n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    \n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) \n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
    "   \n",
    "    ops.reset_default_graph()                         \n",
    "    tf.set_random_seed(1)                             \n",
    "    seed = 3                                        \n",
    "    (m, n_D0, n_R0, n_C0,n_Ch0) = X_train.shape            # shape of input image  \n",
    "    n_y = Y_train.shape[1]                            #no of channels in output \n",
    "    costs = []                                        #list to store cost funtion\n",
    "    shape=[n_D0,n_R0,n_C0]\n",
    "\n",
    "    X, Y =placeholders(shape,n_Ch0, n_y)               #initializing placeholders\n",
    "    \n",
    "    parameters = initialize_parameters(n_Ch0)          #initializing placeholder\n",
    "\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "\n",
    "    cost = com_cost(Z3, Y)                              #Computing cost\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)  #optimizer to optimize and backprop\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "  \n",
    "        sess.run(init)\n",
    "        \n",
    " \n",
    "        for epoch in range(num_epochs): # function to create mini-bataches\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) \n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "           \n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "   \n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.rand(500,30,64,64,3)*100\n",
    "Y_train = np.random.rand(200,1)\n",
    "Y_train = Y_train>=0.6\n",
    "Y_train = Y_train*1\n",
    "X_test  = np.random.rand(50,30,64,64)*100\n",
    "Y_test = np.random.rand(50,1)\n",
    "Y_test = Y_test>=0.6\n",
    "Y_test = Y_test*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
